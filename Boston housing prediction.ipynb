{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston Housing Price dataset for analysis on House Prices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the modules\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
      "57344/57026 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "\n",
    "data = tf.keras.datasets.boston_housing\n",
    "\n",
    "(x_train,y_train),(x_test,y_test)= data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crime</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.23247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.142</td>\n",
       "      <td>91.7</td>\n",
       "      <td>3.9769</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>18.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02177</td>\n",
       "      <td>82.5</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.415</td>\n",
       "      <td>7.610</td>\n",
       "      <td>15.7</td>\n",
       "      <td>6.2700</td>\n",
       "      <td>2.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>395.38</td>\n",
       "      <td>3.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.89822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.631</td>\n",
       "      <td>4.970</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.3325</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>375.52</td>\n",
       "      <td>3.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.515</td>\n",
       "      <td>6.037</td>\n",
       "      <td>34.5</td>\n",
       "      <td>5.9853</td>\n",
       "      <td>5.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>8.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.69311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713</td>\n",
       "      <td>6.376</td>\n",
       "      <td>88.4</td>\n",
       "      <td>2.5671</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>391.43</td>\n",
       "      <td>14.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     crime    ZN  INDUS  CHAS    NOX     RM    AGE     DIS   RAD    TAX  \\\n",
       "0  1.23247   0.0   8.14   0.0  0.538  6.142   91.7  3.9769   4.0  307.0   \n",
       "1  0.02177  82.5   2.03   0.0  0.415  7.610   15.7  6.2700   2.0  348.0   \n",
       "2  4.89822   0.0  18.10   0.0  0.631  4.970  100.0  1.3325  24.0  666.0   \n",
       "3  0.03961   0.0   5.19   0.0  0.515  6.037   34.5  5.9853   5.0  224.0   \n",
       "4  3.69311   0.0  18.10   0.0  0.713  6.376   88.4  2.5671  24.0  666.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     21.0  396.90  18.72  \n",
       "1     14.7  395.38   3.11  \n",
       "2     20.2  375.52   3.26  \n",
       "3     20.2  396.90   8.01  \n",
       "4     20.2  391.43  14.65  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = ['crime', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
    "                'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
    "\n",
    "df_xtrain = pd.DataFrame(x_train,columns=column_names)\n",
    "\n",
    "df_xtrain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data frame contains the following columns:\n",
    "\n",
    "**\n",
    "\n",
    "crim per capita crime rate by town.\n",
    "\n",
    "zn proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "\n",
    "indus proportion of non-retail business acres per town.\n",
    "\n",
    "chas Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).\n",
    "\n",
    "nox nitrogen oxides concentration (parts per 10 million).\n",
    "\n",
    "rm average number of rooms per dwelling.\n",
    "\n",
    "age proportion of owner-occupied units built prior to 1940.\n",
    "\n",
    "dis weighted mean of distances to five Boston employment centres.\n",
    "\n",
    "rad index of accessibility to radial highways.\n",
    "\n",
    "tax full-value property-tax rate per \\$10,000.\n",
    "\n",
    "ptratio pupil-teacher ratio by town.\n",
    "\n",
    "black 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town.\n",
    "\n",
    "lstat lower status of the population (percent).\n",
    "\n",
    "medv median value of owner-occupied homes in \\$1000s.\n",
    "\n",
    "**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crime</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.272246</td>\n",
       "      <td>-0.483615</td>\n",
       "      <td>-0.435762</td>\n",
       "      <td>-0.256833</td>\n",
       "      <td>-0.165227</td>\n",
       "      <td>-0.176443</td>\n",
       "      <td>0.813062</td>\n",
       "      <td>0.116698</td>\n",
       "      <td>-0.626249</td>\n",
       "      <td>-0.595170</td>\n",
       "      <td>1.148500</td>\n",
       "      <td>0.448077</td>\n",
       "      <td>0.825220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.403427</td>\n",
       "      <td>2.991784</td>\n",
       "      <td>-1.333912</td>\n",
       "      <td>-0.256833</td>\n",
       "      <td>-1.215182</td>\n",
       "      <td>1.894346</td>\n",
       "      <td>-1.910361</td>\n",
       "      <td>1.247585</td>\n",
       "      <td>-0.856463</td>\n",
       "      <td>-0.348433</td>\n",
       "      <td>-1.718189</td>\n",
       "      <td>0.431906</td>\n",
       "      <td>-1.329202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.124940</td>\n",
       "      <td>-0.483615</td>\n",
       "      <td>1.028326</td>\n",
       "      <td>-0.256833</td>\n",
       "      <td>0.628642</td>\n",
       "      <td>-1.829688</td>\n",
       "      <td>1.110488</td>\n",
       "      <td>-1.187439</td>\n",
       "      <td>1.675886</td>\n",
       "      <td>1.565287</td>\n",
       "      <td>0.784476</td>\n",
       "      <td>0.220617</td>\n",
       "      <td>-1.308500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.401494</td>\n",
       "      <td>-0.483615</td>\n",
       "      <td>-0.869402</td>\n",
       "      <td>-0.256833</td>\n",
       "      <td>-0.361560</td>\n",
       "      <td>-0.324558</td>\n",
       "      <td>-1.236672</td>\n",
       "      <td>1.107180</td>\n",
       "      <td>-0.511142</td>\n",
       "      <td>-1.094663</td>\n",
       "      <td>0.784476</td>\n",
       "      <td>0.448077</td>\n",
       "      <td>-0.652926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.005634</td>\n",
       "      <td>-0.483615</td>\n",
       "      <td>1.028326</td>\n",
       "      <td>-0.256833</td>\n",
       "      <td>1.328612</td>\n",
       "      <td>0.153642</td>\n",
       "      <td>0.694808</td>\n",
       "      <td>-0.578572</td>\n",
       "      <td>1.675886</td>\n",
       "      <td>1.565287</td>\n",
       "      <td>0.784476</td>\n",
       "      <td>0.389882</td>\n",
       "      <td>0.263497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crime        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0 -0.272246 -0.483615 -0.435762 -0.256833 -0.165227 -0.176443  0.813062   \n",
       "1 -0.403427  2.991784 -1.333912 -0.256833 -1.215182  1.894346 -1.910361   \n",
       "2  0.124940 -0.483615  1.028326 -0.256833  0.628642 -1.829688  1.110488   \n",
       "3 -0.401494 -0.483615 -0.869402 -0.256833 -0.361560 -0.324558 -1.236672   \n",
       "4 -0.005634 -0.483615  1.028326 -0.256833  1.328612  0.153642  0.694808   \n",
       "\n",
       "        DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
       "0  0.116698 -0.626249 -0.595170  1.148500  0.448077  0.825220  \n",
       "1  1.247585 -0.856463 -0.348433 -1.718189  0.431906 -1.329202  \n",
       "2 -1.187439  1.675886  1.565287  0.784476  0.220617 -1.308500  \n",
       "3  1.107180 -0.511142 -1.094663  0.784476  0.448077 -0.652926  \n",
       "4 -0.578572  1.675886  1.565287  0.784476  0.389882  0.263497  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standardized/normalized data\n",
    "\n",
    "mean=x_train.mean(axis=0)\n",
    "\n",
    "std=x_train.std(axis=0)\n",
    "\n",
    "x_train2=(x_train-mean)/std\n",
    "\n",
    "df_train_norm = pd.DataFrame(x_train2, columns=column_names)\n",
    "\n",
    "df_train_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13)\n",
      "(404,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crime</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.23247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.142</td>\n",
       "      <td>91.7</td>\n",
       "      <td>3.9769</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>18.72</td>\n",
       "      <td>15.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02177</td>\n",
       "      <td>82.5</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.415</td>\n",
       "      <td>7.610</td>\n",
       "      <td>15.7</td>\n",
       "      <td>6.2700</td>\n",
       "      <td>2.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>395.38</td>\n",
       "      <td>3.11</td>\n",
       "      <td>42.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.89822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.631</td>\n",
       "      <td>4.970</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.3325</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>375.52</td>\n",
       "      <td>3.26</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.515</td>\n",
       "      <td>6.037</td>\n",
       "      <td>34.5</td>\n",
       "      <td>5.9853</td>\n",
       "      <td>5.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>8.01</td>\n",
       "      <td>21.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.69311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713</td>\n",
       "      <td>6.376</td>\n",
       "      <td>88.4</td>\n",
       "      <td>2.5671</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>391.43</td>\n",
       "      <td>14.65</td>\n",
       "      <td>17.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     crime    ZN  INDUS  CHAS    NOX     RM    AGE     DIS   RAD    TAX  \\\n",
       "0  1.23247   0.0   8.14   0.0  0.538  6.142   91.7  3.9769   4.0  307.0   \n",
       "1  0.02177  82.5   2.03   0.0  0.415  7.610   15.7  6.2700   2.0  348.0   \n",
       "2  4.89822   0.0  18.10   0.0  0.631  4.970  100.0  1.3325  24.0  666.0   \n",
       "3  0.03961   0.0   5.19   0.0  0.515  6.037   34.5  5.9853   5.0  224.0   \n",
       "4  3.69311   0.0  18.10   0.0  0.713  6.376   88.4  2.5671  24.0  666.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  price  \n",
       "0     21.0  396.90  18.72   15.2  \n",
       "1     14.7  395.38   3.11   42.3  \n",
       "2     20.2  375.52   3.26   50.0  \n",
       "3     20.2  396.90   8.01   21.1  \n",
       "4     20.2  391.43  14.65   17.7  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combining x_train and y_train for fidning the corealation between features and sales\n",
    "\n",
    "training_data=np.insert(arr=x_train,values=y_train,axis=1,obj=13)\n",
    "\n",
    "column_names = ['crime' ,'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
    "                'TAX', 'PTRATIO', 'B', 'LSTAT','price']\n",
    "\n",
    "df_train = pd.DataFrame(training_data,columns=column_names)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another more easy way of finding correlation is this:\n",
    "\n",
    "Downhill (negative / positive) linear relationship\n",
    "\n",
    "Uphill (negative / positive) linear relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crime</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>crime</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.192179</td>\n",
       "      <td>0.397419</td>\n",
       "      <td>-0.050828</td>\n",
       "      <td>0.405765</td>\n",
       "      <td>-0.217597</td>\n",
       "      <td>0.344410</td>\n",
       "      <td>-0.378590</td>\n",
       "      <td>0.609689</td>\n",
       "      <td>0.575652</td>\n",
       "      <td>0.273447</td>\n",
       "      <td>-0.390613</td>\n",
       "      <td>0.434384</td>\n",
       "      <td>-0.378498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>-0.192179</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.533823</td>\n",
       "      <td>-0.041981</td>\n",
       "      <td>-0.521713</td>\n",
       "      <td>0.338683</td>\n",
       "      <td>-0.578728</td>\n",
       "      <td>0.650787</td>\n",
       "      <td>-0.311091</td>\n",
       "      <td>-0.303522</td>\n",
       "      <td>-0.403139</td>\n",
       "      <td>0.176006</td>\n",
       "      <td>-0.415237</td>\n",
       "      <td>0.380299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>0.397419</td>\n",
       "      <td>-0.533823</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052839</td>\n",
       "      <td>0.774200</td>\n",
       "      <td>-0.409924</td>\n",
       "      <td>0.656350</td>\n",
       "      <td>-0.725155</td>\n",
       "      <td>0.599226</td>\n",
       "      <td>0.701362</td>\n",
       "      <td>0.379284</td>\n",
       "      <td>-0.372885</td>\n",
       "      <td>0.603129</td>\n",
       "      <td>-0.476743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>-0.050828</td>\n",
       "      <td>-0.041981</td>\n",
       "      <td>0.052839</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.079803</td>\n",
       "      <td>0.040431</td>\n",
       "      <td>0.080488</td>\n",
       "      <td>-0.083101</td>\n",
       "      <td>-0.024851</td>\n",
       "      <td>-0.051343</td>\n",
       "      <td>-0.122008</td>\n",
       "      <td>0.037832</td>\n",
       "      <td>-0.011017</td>\n",
       "      <td>0.168661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>0.405765</td>\n",
       "      <td>-0.521713</td>\n",
       "      <td>0.774200</td>\n",
       "      <td>0.079803</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.335866</td>\n",
       "      <td>0.729338</td>\n",
       "      <td>-0.777062</td>\n",
       "      <td>0.616535</td>\n",
       "      <td>0.673471</td>\n",
       "      <td>0.188160</td>\n",
       "      <td>-0.409479</td>\n",
       "      <td>0.592994</td>\n",
       "      <td>-0.438328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>-0.217597</td>\n",
       "      <td>0.338683</td>\n",
       "      <td>-0.409924</td>\n",
       "      <td>0.040431</td>\n",
       "      <td>-0.335866</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.240875</td>\n",
       "      <td>0.233970</td>\n",
       "      <td>-0.243990</td>\n",
       "      <td>-0.307904</td>\n",
       "      <td>-0.367256</td>\n",
       "      <td>0.145525</td>\n",
       "      <td>-0.610844</td>\n",
       "      <td>0.681483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>0.344410</td>\n",
       "      <td>-0.578728</td>\n",
       "      <td>0.656350</td>\n",
       "      <td>0.080488</td>\n",
       "      <td>0.729338</td>\n",
       "      <td>-0.240875</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.766670</td>\n",
       "      <td>0.462188</td>\n",
       "      <td>0.512746</td>\n",
       "      <td>0.282193</td>\n",
       "      <td>-0.278403</td>\n",
       "      <td>0.590898</td>\n",
       "      <td>-0.364173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>-0.378590</td>\n",
       "      <td>0.650787</td>\n",
       "      <td>-0.725155</td>\n",
       "      <td>-0.083101</td>\n",
       "      <td>-0.777062</td>\n",
       "      <td>0.233970</td>\n",
       "      <td>-0.766670</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.511179</td>\n",
       "      <td>-0.543668</td>\n",
       "      <td>-0.243067</td>\n",
       "      <td>0.295995</td>\n",
       "      <td>-0.507075</td>\n",
       "      <td>0.253900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>0.609689</td>\n",
       "      <td>-0.311091</td>\n",
       "      <td>0.599226</td>\n",
       "      <td>-0.024851</td>\n",
       "      <td>0.616535</td>\n",
       "      <td>-0.243990</td>\n",
       "      <td>0.462188</td>\n",
       "      <td>-0.511179</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.922676</td>\n",
       "      <td>0.449908</td>\n",
       "      <td>-0.478245</td>\n",
       "      <td>0.490250</td>\n",
       "      <td>-0.375515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>0.575652</td>\n",
       "      <td>-0.303522</td>\n",
       "      <td>0.701362</td>\n",
       "      <td>-0.051343</td>\n",
       "      <td>0.673471</td>\n",
       "      <td>-0.307904</td>\n",
       "      <td>0.512746</td>\n",
       "      <td>-0.543668</td>\n",
       "      <td>0.922676</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.440499</td>\n",
       "      <td>-0.471777</td>\n",
       "      <td>0.534752</td>\n",
       "      <td>-0.448737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>0.273447</td>\n",
       "      <td>-0.403139</td>\n",
       "      <td>0.379284</td>\n",
       "      <td>-0.122008</td>\n",
       "      <td>0.188160</td>\n",
       "      <td>-0.367256</td>\n",
       "      <td>0.282193</td>\n",
       "      <td>-0.243067</td>\n",
       "      <td>0.449908</td>\n",
       "      <td>0.440499</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.178060</td>\n",
       "      <td>0.365873</td>\n",
       "      <td>-0.493990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>-0.390613</td>\n",
       "      <td>0.176006</td>\n",
       "      <td>-0.372885</td>\n",
       "      <td>0.037832</td>\n",
       "      <td>-0.409479</td>\n",
       "      <td>0.145525</td>\n",
       "      <td>-0.278403</td>\n",
       "      <td>0.295995</td>\n",
       "      <td>-0.478245</td>\n",
       "      <td>-0.471777</td>\n",
       "      <td>-0.178060</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.376081</td>\n",
       "      <td>0.343953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>0.434384</td>\n",
       "      <td>-0.415237</td>\n",
       "      <td>0.603129</td>\n",
       "      <td>-0.011017</td>\n",
       "      <td>0.592994</td>\n",
       "      <td>-0.610844</td>\n",
       "      <td>0.590898</td>\n",
       "      <td>-0.507075</td>\n",
       "      <td>0.490250</td>\n",
       "      <td>0.534752</td>\n",
       "      <td>0.365873</td>\n",
       "      <td>-0.376081</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.730793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>-0.378498</td>\n",
       "      <td>0.380299</td>\n",
       "      <td>-0.476743</td>\n",
       "      <td>0.168661</td>\n",
       "      <td>-0.438328</td>\n",
       "      <td>0.681483</td>\n",
       "      <td>-0.364173</td>\n",
       "      <td>0.253900</td>\n",
       "      <td>-0.375515</td>\n",
       "      <td>-0.448737</td>\n",
       "      <td>-0.493990</td>\n",
       "      <td>0.343953</td>\n",
       "      <td>-0.730793</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            crime        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "crime    1.000000 -0.192179  0.397419 -0.050828  0.405765 -0.217597  0.344410   \n",
       "ZN      -0.192179  1.000000 -0.533823 -0.041981 -0.521713  0.338683 -0.578728   \n",
       "INDUS    0.397419 -0.533823  1.000000  0.052839  0.774200 -0.409924  0.656350   \n",
       "CHAS    -0.050828 -0.041981  0.052839  1.000000  0.079803  0.040431  0.080488   \n",
       "NOX      0.405765 -0.521713  0.774200  0.079803  1.000000 -0.335866  0.729338   \n",
       "RM      -0.217597  0.338683 -0.409924  0.040431 -0.335866  1.000000 -0.240875   \n",
       "AGE      0.344410 -0.578728  0.656350  0.080488  0.729338 -0.240875  1.000000   \n",
       "DIS     -0.378590  0.650787 -0.725155 -0.083101 -0.777062  0.233970 -0.766670   \n",
       "RAD      0.609689 -0.311091  0.599226 -0.024851  0.616535 -0.243990  0.462188   \n",
       "TAX      0.575652 -0.303522  0.701362 -0.051343  0.673471 -0.307904  0.512746   \n",
       "PTRATIO  0.273447 -0.403139  0.379284 -0.122008  0.188160 -0.367256  0.282193   \n",
       "B       -0.390613  0.176006 -0.372885  0.037832 -0.409479  0.145525 -0.278403   \n",
       "LSTAT    0.434384 -0.415237  0.603129 -0.011017  0.592994 -0.610844  0.590898   \n",
       "price   -0.378498  0.380299 -0.476743  0.168661 -0.438328  0.681483 -0.364173   \n",
       "\n",
       "              DIS       RAD       TAX   PTRATIO         B     LSTAT     price  \n",
       "crime   -0.378590  0.609689  0.575652  0.273447 -0.390613  0.434384 -0.378498  \n",
       "ZN       0.650787 -0.311091 -0.303522 -0.403139  0.176006 -0.415237  0.380299  \n",
       "INDUS   -0.725155  0.599226  0.701362  0.379284 -0.372885  0.603129 -0.476743  \n",
       "CHAS    -0.083101 -0.024851 -0.051343 -0.122008  0.037832 -0.011017  0.168661  \n",
       "NOX     -0.777062  0.616535  0.673471  0.188160 -0.409479  0.592994 -0.438328  \n",
       "RM       0.233970 -0.243990 -0.307904 -0.367256  0.145525 -0.610844  0.681483  \n",
       "AGE     -0.766670  0.462188  0.512746  0.282193 -0.278403  0.590898 -0.364173  \n",
       "DIS      1.000000 -0.511179 -0.543668 -0.243067  0.295995 -0.507075  0.253900  \n",
       "RAD     -0.511179  1.000000  0.922676  0.449908 -0.478245  0.490250 -0.375515  \n",
       "TAX     -0.543668  0.922676  1.000000  0.440499 -0.471777  0.534752 -0.448737  \n",
       "PTRATIO -0.243067  0.449908  0.440499  1.000000 -0.178060  0.365873 -0.493990  \n",
       "B        0.295995 -0.478245 -0.471777 -0.178060  1.000000 -0.376081  0.343953  \n",
       "LSTAT   -0.507075  0.490250  0.534752  0.365873 -0.376081  1.000000 -0.730793  \n",
       "price    0.253900 -0.375515 -0.448737 -0.493990  0.343953 -0.730793  1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_train.copy()\n",
    "\n",
    "# Compute pairwise correlation of columns\n",
    "\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so we can see that a few columns are primary affecting the price of the house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13)\n",
      "(404,)\n",
      "(404, 14)\n",
      "(102, 13)\n",
      "(102,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(training_data.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 323 samples, validate on 81 samples\n",
      "Epoch 1/200\n",
      "323/323 - 1s - loss: 703.5899 - mae: 16.3113 - val_loss: 142.4811 - val_mae: 7.7937\n",
      "Epoch 2/200\n",
      "323/323 - 0s - loss: 139.8305 - mae: 9.5984 - val_loss: 199.7269 - val_mae: 12.4697\n",
      "Epoch 3/200\n",
      "323/323 - 0s - loss: 174.5534 - mae: 11.3023 - val_loss: 193.2601 - val_mae: 12.2388\n",
      "Epoch 4/200\n",
      "323/323 - 0s - loss: 139.6899 - mae: 9.1923 - val_loss: 83.2218 - val_mae: 6.7153\n",
      "Epoch 5/200\n",
      "323/323 - 0s - loss: 147.2872 - mae: 9.9201 - val_loss: 522.4888 - val_mae: 20.0849\n",
      "Epoch 6/200\n",
      "323/323 - 0s - loss: 171.5932 - mae: 9.4899 - val_loss: 158.0215 - val_mae: 11.3560\n",
      "Epoch 7/200\n",
      "323/323 - 0s - loss: 160.0209 - mae: 10.4943 - val_loss: 422.2212 - val_mae: 19.3266\n",
      "Epoch 8/200\n",
      "323/323 - 0s - loss: 142.2727 - mae: 9.1833 - val_loss: 280.2575 - val_mae: 14.2695\n",
      "Epoch 9/200\n",
      "323/323 - 0s - loss: 107.7481 - mae: 8.0523 - val_loss: 86.6481 - val_mae: 7.8007\n",
      "Epoch 10/200\n",
      "323/323 - 0s - loss: 186.9567 - mae: 10.4615 - val_loss: 222.4544 - val_mae: 12.3749\n",
      "Epoch 11/200\n",
      "323/323 - 0s - loss: 139.6095 - mae: 9.5263 - val_loss: 88.3453 - val_mae: 5.8969\n",
      "Epoch 12/200\n",
      "323/323 - 0s - loss: 139.9935 - mae: 9.5037 - val_loss: 101.5846 - val_mae: 8.6971\n",
      "Epoch 13/200\n",
      "323/323 - 0s - loss: 100.9162 - mae: 8.0082 - val_loss: 220.6553 - val_mae: 12.1379\n",
      "Epoch 14/200\n",
      "323/323 - 0s - loss: 159.0007 - mae: 10.6687 - val_loss: 169.1815 - val_mae: 12.0411\n",
      "Epoch 15/200\n",
      "323/323 - 0s - loss: 79.9512 - mae: 6.7435 - val_loss: 129.6877 - val_mae: 7.9651\n",
      "Epoch 16/200\n",
      "323/323 - 0s - loss: 141.9027 - mae: 9.6944 - val_loss: 67.7515 - val_mae: 5.1682\n",
      "Epoch 17/200\n",
      "323/323 - 0s - loss: 149.6510 - mae: 9.4503 - val_loss: 250.1928 - val_mae: 13.6243\n",
      "Epoch 18/200\n",
      "323/323 - 0s - loss: 72.8099 - mae: 6.1589 - val_loss: 157.0887 - val_mae: 9.7906\n",
      "Epoch 19/200\n",
      "323/323 - 0s - loss: 120.1839 - mae: 8.9537 - val_loss: 602.5970 - val_mae: 23.0955\n",
      "Epoch 20/200\n",
      "323/323 - 0s - loss: 125.1855 - mae: 7.6026 - val_loss: 182.1871 - val_mae: 10.7305\n",
      "Epoch 21/200\n",
      "323/323 - 0s - loss: 73.5861 - mae: 6.5694 - val_loss: 167.3189 - val_mae: 11.9810\n",
      "Epoch 22/200\n",
      "323/323 - 0s - loss: 127.4713 - mae: 9.2269 - val_loss: 60.4716 - val_mae: 5.2166\n",
      "Epoch 23/200\n",
      "323/323 - 0s - loss: 90.5771 - mae: 7.1034 - val_loss: 309.7804 - val_mae: 15.7129\n",
      "Epoch 24/200\n",
      "323/323 - 0s - loss: 68.7292 - mae: 5.9803 - val_loss: 282.4419 - val_mae: 15.9358\n",
      "Epoch 25/200\n",
      "323/323 - 0s - loss: 118.9645 - mae: 8.2616 - val_loss: 128.0145 - val_mae: 8.5526\n",
      "Epoch 26/200\n",
      "323/323 - 0s - loss: 81.7601 - mae: 7.1861 - val_loss: 156.8853 - val_mae: 10.9096\n",
      "Epoch 27/200\n",
      "323/323 - 0s - loss: 77.2795 - mae: 6.8594 - val_loss: 301.7291 - val_mae: 15.1118\n",
      "Epoch 28/200\n",
      "323/323 - 0s - loss: 93.7031 - mae: 7.0230 - val_loss: 99.0137 - val_mae: 8.7664\n",
      "Epoch 29/200\n",
      "323/323 - 0s - loss: 81.1916 - mae: 7.1129 - val_loss: 236.9307 - val_mae: 11.8194\n",
      "Epoch 30/200\n",
      "323/323 - 0s - loss: 93.6270 - mae: 7.0411 - val_loss: 65.5570 - val_mae: 6.2319\n",
      "Epoch 31/200\n",
      "323/323 - 0s - loss: 64.8175 - mae: 5.8507 - val_loss: 64.8204 - val_mae: 6.5075\n",
      "Epoch 32/200\n",
      "323/323 - 0s - loss: 70.9643 - mae: 6.6989 - val_loss: 96.0482 - val_mae: 7.0636\n",
      "Epoch 33/200\n",
      "323/323 - 0s - loss: 93.4549 - mae: 7.6811 - val_loss: 140.5104 - val_mae: 9.3248\n",
      "Epoch 34/200\n",
      "323/323 - 0s - loss: 59.6589 - mae: 5.5804 - val_loss: 78.2679 - val_mae: 5.9199\n",
      "Epoch 35/200\n",
      "323/323 - 0s - loss: 101.3828 - mae: 8.0166 - val_loss: 135.0537 - val_mae: 9.3019\n",
      "Epoch 36/200\n",
      "323/323 - 0s - loss: 78.4780 - mae: 6.7321 - val_loss: 54.8638 - val_mae: 5.8301\n",
      "Epoch 37/200\n",
      "323/323 - 0s - loss: 60.4938 - mae: 5.6381 - val_loss: 490.0990 - val_mae: 20.9650\n",
      "Epoch 38/200\n",
      "323/323 - 0s - loss: 88.8875 - mae: 6.5613 - val_loss: 91.9353 - val_mae: 6.9008\n",
      "Epoch 39/200\n",
      "323/323 - 0s - loss: 60.3124 - mae: 5.7442 - val_loss: 73.2054 - val_mae: 5.7628\n",
      "Epoch 40/200\n",
      "323/323 - 0s - loss: 82.2220 - mae: 6.7145 - val_loss: 59.9944 - val_mae: 5.6877\n",
      "Epoch 41/200\n",
      "323/323 - 0s - loss: 41.4617 - mae: 4.5641 - val_loss: 51.3329 - val_mae: 5.5550\n",
      "Epoch 42/200\n",
      "323/323 - 0s - loss: 96.4319 - mae: 7.8451 - val_loss: 216.1101 - val_mae: 12.9676\n",
      "Epoch 43/200\n",
      "323/323 - 0s - loss: 56.7720 - mae: 5.0468 - val_loss: 48.1682 - val_mae: 5.3156\n",
      "Epoch 44/200\n",
      "323/323 - 0s - loss: 75.7672 - mae: 6.4784 - val_loss: 356.6883 - val_mae: 16.9382\n",
      "Epoch 45/200\n",
      "323/323 - 0s - loss: 85.8456 - mae: 6.2787 - val_loss: 97.6531 - val_mae: 7.4329\n",
      "Epoch 46/200\n",
      "323/323 - 0s - loss: 65.4044 - mae: 6.2924 - val_loss: 45.4877 - val_mae: 4.6748\n",
      "Epoch 47/200\n",
      "323/323 - 0s - loss: 57.9074 - mae: 5.3616 - val_loss: 108.1825 - val_mae: 8.0564\n",
      "Epoch 48/200\n",
      "323/323 - 0s - loss: 50.9460 - mae: 5.1227 - val_loss: 219.3165 - val_mae: 13.0531\n",
      "Epoch 49/200\n",
      "323/323 - 0s - loss: 65.0270 - mae: 5.9897 - val_loss: 49.0422 - val_mae: 4.6985\n",
      "Epoch 50/200\n",
      "323/323 - 0s - loss: 67.6252 - mae: 6.3760 - val_loss: 73.6597 - val_mae: 6.0017\n",
      "Epoch 51/200\n",
      "323/323 - 0s - loss: 54.2116 - mae: 5.4898 - val_loss: 62.2366 - val_mae: 5.0522\n",
      "Epoch 52/200\n",
      "323/323 - 0s - loss: 65.3715 - mae: 6.0413 - val_loss: 50.2371 - val_mae: 4.7775\n",
      "Epoch 53/200\n",
      "323/323 - 0s - loss: 39.9063 - mae: 4.4659 - val_loss: 46.7793 - val_mae: 4.3169\n",
      "Epoch 54/200\n",
      "323/323 - 0s - loss: 69.6995 - mae: 6.5117 - val_loss: 82.1476 - val_mae: 6.5019\n",
      "Epoch 55/200\n",
      "323/323 - 0s - loss: 43.9619 - mae: 4.8334 - val_loss: 51.9421 - val_mae: 4.8642\n",
      "Epoch 56/200\n",
      "323/323 - 0s - loss: 73.2594 - mae: 6.5695 - val_loss: 64.1940 - val_mae: 5.4735\n",
      "Epoch 57/200\n",
      "323/323 - 0s - loss: 40.5052 - mae: 4.5345 - val_loss: 88.7458 - val_mae: 7.0077\n",
      "Epoch 58/200\n",
      "323/323 - 0s - loss: 57.5166 - mae: 5.8605 - val_loss: 42.8879 - val_mae: 4.8833\n",
      "Epoch 59/200\n",
      "323/323 - 0s - loss: 49.2087 - mae: 5.1840 - val_loss: 99.6032 - val_mae: 7.4109\n",
      "Epoch 60/200\n",
      "323/323 - 0s - loss: 58.5849 - mae: 5.9984 - val_loss: 52.4567 - val_mae: 4.8391\n",
      "Epoch 61/200\n",
      "323/323 - 0s - loss: 48.8025 - mae: 5.2291 - val_loss: 46.8653 - val_mae: 5.1423\n",
      "Epoch 62/200\n",
      "323/323 - 0s - loss: 49.8744 - mae: 5.2420 - val_loss: 52.2910 - val_mae: 4.8899\n",
      "Epoch 63/200\n",
      "323/323 - 0s - loss: 42.7548 - mae: 4.8702 - val_loss: 195.1385 - val_mae: 11.9499\n",
      "Epoch 64/200\n",
      "323/323 - 0s - loss: 56.6093 - mae: 5.4889 - val_loss: 79.7096 - val_mae: 6.4303\n",
      "Epoch 65/200\n",
      "323/323 - 0s - loss: 46.6607 - mae: 4.8086 - val_loss: 88.7135 - val_mae: 7.1184\n",
      "Epoch 66/200\n",
      "323/323 - 0s - loss: 52.0767 - mae: 5.2224 - val_loss: 65.6705 - val_mae: 6.9692\n",
      "Epoch 67/200\n",
      "323/323 - 0s - loss: 44.1905 - mae: 4.9074 - val_loss: 60.1483 - val_mae: 6.6956\n",
      "Epoch 68/200\n",
      "323/323 - 0s - loss: 46.8094 - mae: 5.1456 - val_loss: 83.1827 - val_mae: 6.6919\n",
      "Epoch 69/200\n",
      "323/323 - 0s - loss: 48.1805 - mae: 5.4270 - val_loss: 61.4767 - val_mae: 6.7415\n",
      "Epoch 70/200\n",
      "323/323 - 0s - loss: 46.6917 - mae: 5.1057 - val_loss: 43.4066 - val_mae: 5.2003\n",
      "Epoch 71/200\n",
      "323/323 - 0s - loss: 52.4554 - mae: 5.3449 - val_loss: 46.9947 - val_mae: 5.1755\n",
      "Epoch 72/200\n",
      "323/323 - 0s - loss: 36.9696 - mae: 4.3463 - val_loss: 45.6737 - val_mae: 5.3852\n",
      "Epoch 73/200\n",
      "323/323 - 0s - loss: 48.9810 - mae: 5.3319 - val_loss: 51.2364 - val_mae: 5.6192\n",
      "Epoch 74/200\n",
      "323/323 - 0s - loss: 35.1856 - mae: 4.1795 - val_loss: 42.0688 - val_mae: 4.1421\n",
      "Epoch 75/200\n",
      "323/323 - 0s - loss: 62.7425 - mae: 5.3441 - val_loss: 52.1751 - val_mae: 4.7087\n",
      "Epoch 76/200\n",
      "323/323 - 0s - loss: 30.8970 - mae: 3.8821 - val_loss: 39.9239 - val_mae: 4.1535\n",
      "Epoch 77/200\n",
      "323/323 - 0s - loss: 46.5749 - mae: 4.8364 - val_loss: 51.6286 - val_mae: 5.5299\n",
      "Epoch 78/200\n",
      "323/323 - 0s - loss: 41.9190 - mae: 4.7726 - val_loss: 38.9538 - val_mae: 4.0687\n",
      "Epoch 79/200\n",
      "323/323 - 0s - loss: 44.3996 - mae: 4.8978 - val_loss: 44.5758 - val_mae: 5.4312\n",
      "Epoch 80/200\n",
      "323/323 - 0s - loss: 42.7774 - mae: 4.9528 - val_loss: 83.7215 - val_mae: 6.9015\n",
      "Epoch 81/200\n",
      "323/323 - 0s - loss: 42.0274 - mae: 4.7592 - val_loss: 58.4015 - val_mae: 6.6375\n",
      "Epoch 82/200\n",
      "323/323 - 0s - loss: 46.1285 - mae: 5.2363 - val_loss: 119.4776 - val_mae: 10.2678\n",
      "Epoch 83/200\n",
      "323/323 - 0s - loss: 40.9762 - mae: 4.6807 - val_loss: 76.1601 - val_mae: 7.5492\n",
      "Epoch 84/200\n",
      "323/323 - 0s - loss: 33.4151 - mae: 4.1069 - val_loss: 251.7443 - val_mae: 14.7461\n",
      "Epoch 85/200\n",
      "323/323 - 0s - loss: 50.2279 - mae: 4.9755 - val_loss: 33.7470 - val_mae: 4.0062\n",
      "Epoch 86/200\n",
      "323/323 - 0s - loss: 44.1420 - mae: 4.9406 - val_loss: 39.2106 - val_mae: 4.1741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/200\n",
      "323/323 - 0s - loss: 36.7117 - mae: 4.4967 - val_loss: 57.0832 - val_mae: 5.2120\n",
      "Epoch 88/200\n",
      "323/323 - 0s - loss: 31.3868 - mae: 4.1238 - val_loss: 33.1440 - val_mae: 4.0149\n",
      "Epoch 89/200\n",
      "323/323 - 0s - loss: 44.7081 - mae: 5.0175 - val_loss: 44.4883 - val_mae: 4.3827\n",
      "Epoch 90/200\n",
      "323/323 - 0s - loss: 27.9247 - mae: 3.8694 - val_loss: 51.0696 - val_mae: 6.1109\n",
      "Epoch 91/200\n",
      "323/323 - 0s - loss: 42.1326 - mae: 5.0074 - val_loss: 46.0293 - val_mae: 4.5336\n",
      "Epoch 92/200\n",
      "323/323 - 0s - loss: 33.0598 - mae: 4.1806 - val_loss: 45.3501 - val_mae: 4.6371\n",
      "Epoch 93/200\n",
      "323/323 - 0s - loss: 33.7094 - mae: 4.2465 - val_loss: 36.1778 - val_mae: 4.2001\n",
      "Epoch 94/200\n",
      "323/323 - 0s - loss: 46.8934 - mae: 5.4861 - val_loss: 56.5195 - val_mae: 6.5581\n",
      "Epoch 95/200\n",
      "323/323 - 0s - loss: 33.5823 - mae: 4.4059 - val_loss: 36.4666 - val_mae: 4.8025\n",
      "Epoch 96/200\n",
      "323/323 - 0s - loss: 44.1954 - mae: 4.8126 - val_loss: 45.6298 - val_mae: 5.8134\n",
      "Epoch 97/200\n",
      "323/323 - 0s - loss: 37.1207 - mae: 4.5877 - val_loss: 32.4622 - val_mae: 4.2364\n",
      "Epoch 98/200\n",
      "323/323 - 0s - loss: 29.4041 - mae: 4.0429 - val_loss: 32.0480 - val_mae: 3.8626\n",
      "Epoch 99/200\n",
      "323/323 - 0s - loss: 47.4356 - mae: 5.1072 - val_loss: 34.0270 - val_mae: 3.9260\n",
      "Epoch 100/200\n",
      "323/323 - 0s - loss: 30.7730 - mae: 3.9424 - val_loss: 138.8368 - val_mae: 10.1651\n",
      "Epoch 101/200\n",
      "323/323 - 0s - loss: 35.8679 - mae: 4.1508 - val_loss: 92.9285 - val_mae: 8.6534\n",
      "Epoch 102/200\n",
      "323/323 - 0s - loss: 35.6116 - mae: 4.1687 - val_loss: 40.0311 - val_mae: 4.2138\n",
      "Epoch 103/200\n",
      "323/323 - 0s - loss: 33.3819 - mae: 4.2314 - val_loss: 36.7827 - val_mae: 4.2374\n",
      "Epoch 104/200\n",
      "323/323 - 0s - loss: 24.4093 - mae: 3.5446 - val_loss: 113.8782 - val_mae: 9.1964\n",
      "Epoch 105/200\n",
      "323/323 - 0s - loss: 45.2154 - mae: 4.8164 - val_loss: 47.0139 - val_mae: 4.7931\n",
      "Epoch 106/200\n",
      "323/323 - 0s - loss: 33.1585 - mae: 4.1091 - val_loss: 35.5100 - val_mae: 4.9949\n",
      "Epoch 107/200\n",
      "323/323 - 0s - loss: 35.8361 - mae: 4.4433 - val_loss: 29.3770 - val_mae: 3.8977\n",
      "Epoch 108/200\n",
      "323/323 - 0s - loss: 30.2027 - mae: 4.0679 - val_loss: 50.9939 - val_mae: 6.1875\n",
      "Epoch 109/200\n",
      "323/323 - 0s - loss: 49.5458 - mae: 4.9526 - val_loss: 30.6598 - val_mae: 4.4351\n",
      "Epoch 110/200\n",
      "323/323 - 0s - loss: 30.9467 - mae: 4.0511 - val_loss: 55.7782 - val_mae: 6.4867\n",
      "Epoch 111/200\n",
      "323/323 - 0s - loss: 29.7639 - mae: 3.9290 - val_loss: 67.1934 - val_mae: 5.9145\n",
      "Epoch 112/200\n",
      "323/323 - 0s - loss: 33.0770 - mae: 4.1366 - val_loss: 29.6837 - val_mae: 4.3119\n",
      "Epoch 113/200\n",
      "323/323 - 0s - loss: 31.7657 - mae: 4.0334 - val_loss: 29.6697 - val_mae: 4.4074\n",
      "Epoch 114/200\n",
      "323/323 - 0s - loss: 29.7631 - mae: 4.0452 - val_loss: 41.6782 - val_mae: 4.6428\n",
      "Epoch 115/200\n",
      "323/323 - 0s - loss: 32.3238 - mae: 4.3631 - val_loss: 58.6009 - val_mae: 5.7316\n",
      "Epoch 116/200\n",
      "323/323 - 0s - loss: 35.2926 - mae: 4.3183 - val_loss: 43.7229 - val_mae: 5.8171\n",
      "Epoch 117/200\n",
      "323/323 - 0s - loss: 33.0166 - mae: 4.3009 - val_loss: 30.6489 - val_mae: 3.9900\n",
      "Epoch 118/200\n",
      "323/323 - 0s - loss: 36.2106 - mae: 4.5217 - val_loss: 108.0687 - val_mae: 8.8964\n",
      "Epoch 119/200\n",
      "323/323 - 0s - loss: 31.1247 - mae: 4.0208 - val_loss: 77.9877 - val_mae: 7.2050\n",
      "Epoch 120/200\n",
      "323/323 - 0s - loss: 32.4799 - mae: 4.0791 - val_loss: 29.7304 - val_mae: 4.5390\n",
      "Epoch 121/200\n",
      "323/323 - 0s - loss: 26.7215 - mae: 3.7269 - val_loss: 35.6053 - val_mae: 4.1078\n",
      "Epoch 122/200\n",
      "323/323 - 0s - loss: 32.8402 - mae: 4.3461 - val_loss: 28.5050 - val_mae: 3.6918\n",
      "Epoch 123/200\n",
      "323/323 - 0s - loss: 27.7812 - mae: 3.8959 - val_loss: 61.4059 - val_mae: 6.0310\n",
      "Epoch 124/200\n",
      "323/323 - 0s - loss: 28.5238 - mae: 4.0672 - val_loss: 24.4591 - val_mae: 3.9033\n",
      "Epoch 125/200\n",
      "323/323 - 0s - loss: 32.9247 - mae: 4.2315 - val_loss: 36.0261 - val_mae: 4.9013\n",
      "Epoch 126/200\n",
      "323/323 - 0s - loss: 21.4450 - mae: 3.3568 - val_loss: 38.7330 - val_mae: 4.4221\n",
      "Epoch 127/200\n",
      "323/323 - 0s - loss: 40.5374 - mae: 4.6819 - val_loss: 74.0575 - val_mae: 6.5880\n",
      "Epoch 128/200\n",
      "323/323 - 0s - loss: 27.0296 - mae: 3.7442 - val_loss: 43.1051 - val_mae: 4.7149\n",
      "Epoch 129/200\n",
      "323/323 - 0s - loss: 25.8204 - mae: 3.8371 - val_loss: 27.3596 - val_mae: 4.2358\n",
      "Epoch 130/200\n",
      "323/323 - 0s - loss: 30.7312 - mae: 3.9734 - val_loss: 28.9059 - val_mae: 3.6752\n",
      "Epoch 131/200\n",
      "323/323 - 0s - loss: 24.9140 - mae: 3.7231 - val_loss: 27.4354 - val_mae: 4.2793\n",
      "Epoch 132/200\n",
      "323/323 - 0s - loss: 32.2597 - mae: 4.1075 - val_loss: 33.2984 - val_mae: 4.9987\n",
      "Epoch 133/200\n",
      "323/323 - 0s - loss: 25.1192 - mae: 3.6466 - val_loss: 31.4277 - val_mae: 4.6444\n",
      "Epoch 134/200\n",
      "323/323 - 0s - loss: 36.9296 - mae: 4.6902 - val_loss: 25.9120 - val_mae: 3.6209\n",
      "Epoch 135/200\n",
      "323/323 - 0s - loss: 21.5512 - mae: 3.2524 - val_loss: 38.7973 - val_mae: 5.3326\n",
      "Epoch 136/200\n",
      "323/323 - 0s - loss: 35.1238 - mae: 4.4743 - val_loss: 30.1652 - val_mae: 4.5706\n",
      "Epoch 137/200\n",
      "323/323 - 0s - loss: 20.9717 - mae: 3.3931 - val_loss: 27.3505 - val_mae: 3.7239\n",
      "Epoch 138/200\n",
      "323/323 - 0s - loss: 28.5248 - mae: 3.9585 - val_loss: 25.8479 - val_mae: 4.1239\n",
      "Epoch 139/200\n",
      "323/323 - 0s - loss: 24.0894 - mae: 3.7613 - val_loss: 28.4399 - val_mae: 4.4692\n",
      "Epoch 140/200\n",
      "323/323 - 0s - loss: 32.9710 - mae: 4.2472 - val_loss: 29.1669 - val_mae: 4.2662\n",
      "Epoch 141/200\n",
      "323/323 - 0s - loss: 25.1398 - mae: 3.7008 - val_loss: 63.9517 - val_mae: 6.2886\n",
      "Epoch 142/200\n",
      "323/323 - 0s - loss: 31.2881 - mae: 4.0877 - val_loss: 22.4663 - val_mae: 3.5980\n",
      "Epoch 143/200\n",
      "323/323 - 0s - loss: 28.8948 - mae: 3.7901 - val_loss: 39.4534 - val_mae: 4.6100\n",
      "Epoch 144/200\n",
      "323/323 - 0s - loss: 25.5738 - mae: 3.6597 - val_loss: 22.2457 - val_mae: 3.4049\n",
      "Epoch 145/200\n",
      "323/323 - 0s - loss: 31.0554 - mae: 4.0858 - val_loss: 40.3273 - val_mae: 4.6575\n",
      "Epoch 146/200\n",
      "323/323 - 0s - loss: 21.7219 - mae: 3.3944 - val_loss: 35.8667 - val_mae: 4.2288\n",
      "Epoch 147/200\n",
      "323/323 - 0s - loss: 28.6432 - mae: 4.0327 - val_loss: 32.4938 - val_mae: 3.9621\n",
      "Epoch 148/200\n",
      "323/323 - 0s - loss: 24.3489 - mae: 3.6943 - val_loss: 21.4609 - val_mae: 3.4582\n",
      "Epoch 149/200\n",
      "323/323 - 0s - loss: 22.1219 - mae: 3.4439 - val_loss: 26.9003 - val_mae: 4.0024\n",
      "Epoch 150/200\n",
      "323/323 - 0s - loss: 25.1592 - mae: 3.6539 - val_loss: 30.6930 - val_mae: 4.4914\n",
      "Epoch 151/200\n",
      "323/323 - 0s - loss: 26.2805 - mae: 3.7318 - val_loss: 20.7937 - val_mae: 3.5246\n",
      "Epoch 152/200\n",
      "323/323 - 0s - loss: 27.4726 - mae: 3.7248 - val_loss: 23.7349 - val_mae: 3.3870\n",
      "Epoch 153/200\n",
      "323/323 - 0s - loss: 26.3582 - mae: 3.7886 - val_loss: 43.3839 - val_mae: 5.3844\n",
      "Epoch 154/200\n",
      "323/323 - 0s - loss: 19.0439 - mae: 3.2003 - val_loss: 20.6232 - val_mae: 3.5084\n",
      "Epoch 155/200\n",
      "323/323 - 0s - loss: 22.1363 - mae: 3.6370 - val_loss: 32.2019 - val_mae: 4.1391\n",
      "Epoch 156/200\n",
      "323/323 - 0s - loss: 25.4690 - mae: 3.7528 - val_loss: 21.6265 - val_mae: 3.5770\n",
      "Epoch 157/200\n",
      "323/323 - 0s - loss: 19.4831 - mae: 3.2658 - val_loss: 22.6813 - val_mae: 3.5523\n",
      "Epoch 158/200\n",
      "323/323 - 0s - loss: 30.8187 - mae: 4.1887 - val_loss: 20.4152 - val_mae: 3.4342\n",
      "Epoch 159/200\n",
      "323/323 - 0s - loss: 25.1725 - mae: 3.7178 - val_loss: 43.5761 - val_mae: 5.8871\n",
      "Epoch 160/200\n",
      "323/323 - 0s - loss: 22.8360 - mae: 3.4481 - val_loss: 34.0031 - val_mae: 4.9006\n",
      "Epoch 161/200\n",
      "323/323 - 0s - loss: 25.7626 - mae: 3.6168 - val_loss: 18.8101 - val_mae: 3.4640\n",
      "Epoch 162/200\n",
      "323/323 - 0s - loss: 23.0032 - mae: 3.6457 - val_loss: 18.8724 - val_mae: 3.1657\n",
      "Epoch 163/200\n",
      "323/323 - 0s - loss: 28.1861 - mae: 3.8177 - val_loss: 22.3086 - val_mae: 3.6658\n",
      "Epoch 164/200\n",
      "323/323 - 0s - loss: 17.0733 - mae: 2.9389 - val_loss: 39.2827 - val_mae: 4.6185\n",
      "Epoch 165/200\n",
      "323/323 - 0s - loss: 23.4144 - mae: 3.5421 - val_loss: 92.4523 - val_mae: 8.4271\n",
      "Epoch 166/200\n",
      "323/323 - 0s - loss: 30.0886 - mae: 3.8577 - val_loss: 28.4820 - val_mae: 4.0039\n",
      "Epoch 167/200\n",
      "323/323 - 0s - loss: 19.0208 - mae: 3.2378 - val_loss: 21.4921 - val_mae: 3.7944\n",
      "Epoch 168/200\n",
      "323/323 - 0s - loss: 20.1347 - mae: 3.3531 - val_loss: 24.7057 - val_mae: 3.5651\n",
      "Epoch 169/200\n",
      "323/323 - 0s - loss: 24.1578 - mae: 3.4549 - val_loss: 16.7119 - val_mae: 3.3231\n",
      "Epoch 170/200\n",
      "323/323 - 0s - loss: 22.2025 - mae: 3.1721 - val_loss: 23.8062 - val_mae: 3.5579\n",
      "Epoch 171/200\n",
      "323/323 - 0s - loss: 21.5071 - mae: 3.4274 - val_loss: 18.9599 - val_mae: 3.1616\n",
      "Epoch 172/200\n",
      "323/323 - 0s - loss: 27.9113 - mae: 3.8277 - val_loss: 44.2483 - val_mae: 5.0247\n",
      "Epoch 173/200\n",
      "323/323 - 0s - loss: 18.2251 - mae: 3.0509 - val_loss: 19.5410 - val_mae: 3.5436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174/200\n",
      "323/323 - 0s - loss: 18.2317 - mae: 3.1036 - val_loss: 20.5311 - val_mae: 3.3383\n",
      "Epoch 175/200\n",
      "323/323 - 0s - loss: 17.6954 - mae: 3.1519 - val_loss: 26.1130 - val_mae: 4.1567\n",
      "Epoch 176/200\n",
      "323/323 - 0s - loss: 23.3527 - mae: 3.5697 - val_loss: 36.4252 - val_mae: 5.0604\n",
      "Epoch 177/200\n",
      "323/323 - 0s - loss: 18.3225 - mae: 2.9623 - val_loss: 47.8225 - val_mae: 5.8023\n",
      "Epoch 178/200\n",
      "323/323 - 0s - loss: 25.4114 - mae: 3.7382 - val_loss: 26.0048 - val_mae: 4.2728\n",
      "Epoch 179/200\n",
      "323/323 - 0s - loss: 19.5144 - mae: 3.2163 - val_loss: 21.0023 - val_mae: 3.5963\n",
      "Epoch 180/200\n",
      "323/323 - 0s - loss: 20.6840 - mae: 3.3801 - val_loss: 23.9105 - val_mae: 3.5294\n",
      "Epoch 181/200\n",
      "323/323 - 0s - loss: 16.6781 - mae: 3.0055 - val_loss: 17.5229 - val_mae: 3.3642\n",
      "Epoch 182/200\n",
      "323/323 - 0s - loss: 25.8177 - mae: 3.6448 - val_loss: 33.2265 - val_mae: 4.6651\n",
      "Epoch 183/200\n",
      "323/323 - 0s - loss: 19.9072 - mae: 3.0897 - val_loss: 18.1756 - val_mae: 3.1778\n",
      "Epoch 184/200\n",
      "323/323 - 0s - loss: 15.8186 - mae: 2.9295 - val_loss: 48.5885 - val_mae: 5.9466\n",
      "Epoch 185/200\n",
      "323/323 - 0s - loss: 20.1798 - mae: 3.2097 - val_loss: 42.7831 - val_mae: 5.1300\n",
      "Epoch 186/200\n",
      "323/323 - 0s - loss: 17.6860 - mae: 3.1358 - val_loss: 19.3949 - val_mae: 3.2857\n",
      "Epoch 187/200\n",
      "323/323 - 0s - loss: 21.8301 - mae: 3.4480 - val_loss: 18.3149 - val_mae: 3.1919\n",
      "Epoch 188/200\n",
      "323/323 - 0s - loss: 21.0653 - mae: 3.4437 - val_loss: 16.9879 - val_mae: 3.1465\n",
      "Epoch 189/200\n",
      "323/323 - 0s - loss: 23.4527 - mae: 3.4234 - val_loss: 19.0885 - val_mae: 3.5485\n",
      "Epoch 190/200\n",
      "323/323 - 0s - loss: 15.7685 - mae: 2.9561 - val_loss: 25.3980 - val_mae: 4.2834\n",
      "Epoch 191/200\n",
      "323/323 - 0s - loss: 19.6797 - mae: 3.3839 - val_loss: 53.7704 - val_mae: 5.5006\n",
      "Epoch 192/200\n",
      "323/323 - 0s - loss: 21.4919 - mae: 3.3563 - val_loss: 77.7902 - val_mae: 7.6455\n",
      "Epoch 193/200\n",
      "323/323 - 0s - loss: 21.1670 - mae: 3.2426 - val_loss: 41.1770 - val_mae: 5.5066\n",
      "Epoch 194/200\n",
      "323/323 - 0s - loss: 17.6840 - mae: 3.1293 - val_loss: 21.0516 - val_mae: 3.3654\n",
      "Epoch 195/200\n",
      "323/323 - 0s - loss: 17.8968 - mae: 3.2387 - val_loss: 26.2810 - val_mae: 3.8735\n",
      "Epoch 196/200\n",
      "323/323 - 0s - loss: 20.0125 - mae: 3.1916 - val_loss: 24.7223 - val_mae: 3.8382\n",
      "Epoch 197/200\n",
      "323/323 - 0s - loss: 21.1988 - mae: 3.3431 - val_loss: 17.6927 - val_mae: 3.2617\n",
      "Epoch 198/200\n",
      "323/323 - 0s - loss: 16.9562 - mae: 3.0845 - val_loss: 19.6860 - val_mae: 3.6305\n",
      "Epoch 199/200\n",
      "323/323 - 0s - loss: 17.6147 - mae: 3.0220 - val_loss: 31.5627 - val_mae: 4.3509\n",
      "Epoch 200/200\n",
      "323/323 - 0s - loss: 22.4942 - mae: 3.4476 - val_loss: 14.9916 - val_mae: 3.0318\n"
     ]
    }
   ],
   "source": [
    "Epochs=200\n",
    "\n",
    "Loss=\"mse\"\n",
    "\n",
    "model=tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(64,activation=tf.nn.relu))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "model.compile(optimizer='rmsprop',loss=Loss,metrics=['mae'])\n",
    "\n",
    "history=model.fit(x_train,y_train,epochs=Epochs,validation_split=0.2,verbose=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 49us/sample - loss: 40.3048 - mae: 3.5365\n",
      "mae= 3.5364566\n"
     ]
    }
   ],
   "source": [
    "loss,mae=model.evaluate(x_test,y_test)\n",
    "\n",
    "print('mae=', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of prices of all the data =  22.53280632411067\n"
     ]
    }
   ],
   "source": [
    "all_price_sum = y_train.sum()+y_test.sum()\n",
    "Number_of_prices = y_train.size+y_test.size  #number of all labels\n",
    "\n",
    "print(\"Average of prices of all the data = \",all_price_sum/Number_of_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The average of price is 22,000 while our mean absolute error is around 3 to 4.5k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
